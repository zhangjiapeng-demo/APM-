import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from difflib import get_close_matches
import numpy as np

# 1. é¡µé¢é…ç½®
st.set_page_config(page_title="APMæ•°æ®å¯è§†åŒ– Pro", layout="wide", page_icon="ğŸ“Š")

# --- ğŸ¨ æ ·å¼ä¼˜åŒ– ---
st.markdown("""
    <style>
        .block-container { text-align: center; padding-top: 2rem; }
        h1, h2, h3, h4, h5, h6 { text-align: center !important; width: 100%; }
        div[data-testid="stDataFrame"] { display: inline-block; text-align: left; margin: 0 auto; }
        div.stDownloadButton { text-align: center; }
        .metric-card {
            background-color: #f0f2f6; padding: 15px; border-radius: 8px; margin: 10px 0; text-align: left;
        }
    </style>
""", unsafe_allow_html=True)

st.title("ğŸ“Š APM æ€§èƒ½åˆ†æ (å®Œæ•´ä¿®å¤ç‰ˆ)")

# --- ç¿»è¯‘å­—å…¸ ---
TRANS_MAP = {
    "cpu_app": "åº”ç”¨CPU", "cpu_sys": "ç³»ç»ŸCPU", "mem_total": "æ€»å†…å­˜", "mem_swap": "äº¤æ¢å†…å­˜",
    "battery_level": "ç”µé‡", "battery_tem": "ç”µæ± æ¸©åº¦", "fps": "å¸§ç‡FPS", "gpu": "GPU",
    "timestamp": "é‡‡é›†æ—¶é—´", "time": "æ—¶é—´", "value": "æ•°å€¼",
    "upflow": "ä¸Šè¡Œæµé‡", "downflow": "ä¸‹è¡Œæµé‡", "net_usage": "ç½‘ç»œä½¿ç”¨ç‡",
    "mem_rss": "ç‰©ç†å†…å­˜(RSS)", "mem_vss": "è™šæ‹Ÿå†…å­˜(VSS)", "heap_size": "å †å†…å­˜", "heap_alloc": "å·²ç”¨å †å†…å­˜"
}


def get_smart_name(name):
    name_str = str(name).strip()
    if name_str in TRANS_MAP: return TRANS_MAP[name_str]
    if name_str.lower() in TRANS_MAP: return TRANS_MAP[name_str.lower()]
    matches = get_close_matches(name_str.lower(), TRANS_MAP.keys(), n=1, cutoff=0.8)
    if matches: return TRANS_MAP[matches[0]]
    return name_str


# --- ç¼“å­˜è¯»å– ---
def get_file_info(file):
    if file.name.endswith('.csv'): return None, ["CSVæ•°æ®"]
    xls = pd.ExcelFile(file)
    return xls, xls.sheet_names


@st.cache_data(ttl=3600)
def load_data_from_sheet(file, sheet_name, is_csv):
    try:
        if is_csv:
            file.seek(0);
            return pd.read_csv(file)
        return pd.read_excel(file, sheet_name=sheet_name)
    except:
        return pd.DataFrame()


# --- ğŸ§  å†…å­˜è¯Šæ–­é€»è¾‘ ---
def diagnose_memory(df, mem_col, total_mem_limit=None):
    result = {"status": "normal", "messages": [], "slope": 0.0, "is_oom_risk": False}
    series = df[mem_col].dropna()
    if len(series) < 10: return result, (0, 0)

    y = series.values
    x = np.arange(len(y))
    slope, intercept = np.polyfit(x, y, 1)
    result["slope"] = slope

    start_val = np.mean(y[:10])
    end_val = np.mean(y[-10:])
    growth_rate = (end_val - start_val) / (start_val + 1e-5)

    if slope > 0.05 and growth_rate > 0.1:
        result["status"] = "warning"
        result["messages"].append(f"ğŸ“‰ **æ³„æ¼é£é™©**: å†…å­˜å‘ˆä¸Šå‡è¶‹åŠ¿ (å¢é•¿ç‡ {growth_rate:.1%})")
        if slope > 0.5:
            result["status"] = "critical"
            result["messages"].append("ğŸš« **ä¸¥é‡æ³„æ¼**: å¢é•¿æå¿«ï¼Œè¯·æ£€æŸ¥ä»£ç ï¼")
    else:
        result["messages"].append("âœ… **è¶‹åŠ¿æ­£å¸¸**: æœªæ£€æµ‹åˆ°æŒç»­æ³„æ¼")

    max_val = np.max(y)
    if total_mem_limit and total_mem_limit > 0:
        usage_ratio = max_val / total_mem_limit
        if usage_ratio > 0.95:
            result["is_oom_risk"] = True
            result["messages"].append(f"ğŸ”¥ **OOM è­¦å‘Š**: å³°å€¼å·²è¾¾ä¸Šé™çš„ {usage_ratio:.1%}")

    return result, (slope, intercept)


# --- ä¸»ç¨‹åº ---
uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ æµ‹è¯•æ•°æ® (Excel/CSV)", type=['xlsx', 'xls', 'csv'])

if uploaded_file:
    try:
        xls_obj, sheet_names = get_file_info(uploaded_file)

        with st.sidebar:
            st.header("âš™ï¸ æ§åˆ¶é¢æ¿")

            # 1. æ•°æ®æº
            sheet_alias = [get_smart_name(s) for s in sheet_names]
            selected_alias = st.selectbox("æ•°æ®é¡¹:", sheet_alias)
            selected_sheet_raw = sheet_names[sheet_alias.index(selected_alias)]

            is_csv = uploaded_file.name.endswith('.csv')
            df_raw = load_data_from_sheet(uploaded_file, selected_sheet_raw, is_csv)

            if df_raw.empty: st.error("æ•°æ®ä¸ºç©º"); st.stop()

            # 2. è½´è®¾ç½®
            columns = df_raw.columns.tolist()
            default_x = columns[0]
            for col in columns:
                if any(k in str(col).lower() for k in ['time', 'date', 'æ—¶é—´']):
                    default_x = col;
                    break

            col_map = {c: get_smart_name(c) for c in columns}
            x_col = st.selectbox("X è½´ (æ—¶é—´):", columns, index=columns.index(default_x),
                                 format_func=lambda x: col_map[x])

            st.divider()

            # 3. è½´é…ç½®
            st.subheader("ğŸ“ˆ è½´é…ç½®")
            numeric_cols = df_raw.select_dtypes(include=['number']).columns.tolist()
            valid_y = [c for c in columns if c in numeric_cols and c != x_col]

            y_left = st.multiselect("â¬…ï¸ å·¦ Y è½´:", valid_y, default=[valid_y[0]] if valid_y else [],
                                    format_func=lambda x: col_map[x])
            remaining_y = [c for c in valid_y if c not in y_left]
            y_right = st.multiselect("â¡ï¸ å³ Y è½´:", remaining_y, format_func=lambda x: col_map[x])

            st.divider()

            # 4. åŠŸèƒ½å¼€å…³
            st.subheader("ğŸ› ï¸ é«˜çº§åŠŸèƒ½")
            st.markdown("**è¾…åŠ©çº¿æ˜¾ç¤º:**")
            col_opt1, col_opt2, col_opt3 = st.columns(3)
            show_avg = col_opt1.checkbox("å¹³å‡å€¼", False)
            show_max = col_opt2.checkbox("æœ€å¤§å€¼", False)
            show_min = col_opt3.checkbox("æœ€å°å€¼", False)

            st.markdown("**æ™ºèƒ½è¯Šæ–­:**")
            enable_diag = st.checkbox("å¼€å¯å†…å­˜æ³„æ¼/OOMåˆ†æ", False)
            mem_limit_input = 0.0
            target_mem_col = None
            if enable_diag:
                mem_candidates = [c for c in (y_left + y_right) if "mem" in c.lower() or "å†…å­˜" in str(col_map[c])]
                default_mem = mem_candidates[0] if mem_candidates else (y_left[0] if y_left else None)
                target_mem_col = st.selectbox("è¯Šæ–­ç›®æ ‡åˆ—:", y_left + y_right,
                                              index=(y_left + y_right).index(default_mem) if default_mem else 0,
                                              format_func=lambda x: col_map[x])
                mem_limit_input = st.number_input("OOM é˜ˆå€¼ (0ä¸æ£€æµ‹):", value=0.0)

        if x_col and (y_left or y_right):
            df = df_raw.copy()
            df[x_col] = pd.to_datetime(df[x_col], errors='coerce')
            df = df.dropna(subset=[x_col]).sort_values(by=x_col)

            # --- æ—¶é—´ç­›é€‰ ---
            min_date, max_date = df[x_col].min(), df[x_col].max()
            if min_date and max_date and min_date != max_date:
                range_start, range_end = st.slider(
                    "â³ æ—¶é—´èŒƒå›´ç­›é€‰:",
                    min_value=min_date.to_pydatetime(),
                    max_value=max_date.to_pydatetime(),
                    value=(min_date.to_pydatetime(), max_date.to_pydatetime()),
                    format="MM-DD HH:mm"
                )
                df = df[(df[x_col] >= range_start) & (df[x_col] <= range_end)]

            # --- æ™ºèƒ½è¯Šæ–­ ---
            diag_result = None;
            trend_line = None
            if enable_diag and target_mem_col and not df.empty:
                diag_result, (slope, intercept) = diagnose_memory(df, target_mem_col, mem_limit_input)
                trend_line = slope * np.arange(len(df)) + intercept

            # --- ç»˜å›¾ ---
            fig = make_subplots(specs=[[{"secondary_y": True}]])
            time_fmt = "%Y.%m.%d %H:%M:%S"
            colors = px.colors.qualitative.Plotly


            def add_series(col_name, is_secondary, color_idx):
                series_color = colors[color_idx % len(colors)]
                # ç”»ä¸»æ›²çº¿
                fig.add_trace(go.Scatter(
                    x=df[x_col], y=df[col_name], name=f"{col_map[col_name]}",
                    mode='lines', line=dict(width=2, color=series_color, dash='dot' if is_secondary else 'solid')
                ), secondary_y=is_secondary)

                # ç”»è¯Šæ–­è¶‹åŠ¿çº¿
                if enable_diag and col_name == target_mem_col and trend_line is not None and not is_secondary:
                    fig.add_trace(go.Scatter(
                        x=df[x_col], y=trend_line, name="ğŸ“ˆ è¶‹åŠ¿çº¿",
                        mode='lines', line=dict(width=2, color='red', dash='dash'), opacity=0.7
                    ), secondary_y=False)

                # ç”» Min/Max/Avg è¾…åŠ©çº¿
                stats_val = []
                if show_avg: stats_val.append((df[col_name].mean(), "Avg", "dash"))
                if show_max: stats_val.append((df[col_name].max(), "Max", "dot"))
                if show_min: stats_val.append((df[col_name].min(), "Min", "dot"))

                for val, label, dash_style in stats_val:
                    fig.add_hline(
                        y=val, line_dash=dash_style, line_width=1, line_color=series_color,
                        annotation_text=f"{label}:{val:.2f}",
                        annotation_position="top right" if not is_secondary else "top left",
                        secondary_y=is_secondary
                    )


            for i, col in enumerate(y_left): add_series(col, False, i)
            for j, col in enumerate(y_right): add_series(col, True, len(y_left) + j)

            if enable_diag and mem_limit_input > 0:
                fig.add_hline(y=mem_limit_input, line_dash="solid", line_color="red", line_width=2,
                              annotation_text=f"OOMé˜ˆå€¼:{mem_limit_input}")

            fig.update_layout(
                title_text=f"{get_smart_name(selected_sheet_raw)} è¶‹åŠ¿å›¾",
                title_x=0.5, title_font=dict(size=20),
                hovermode="x unified", height=550,
                legend=dict(orientation="h", y=1.1, x=0.5, xanchor='center'),
                margin=dict(l=20, r=20, t=80, b=20)
            )
            fig.update_xaxes(tickformat=time_fmt, tickangle=-30)
            fig.update_yaxes(title_text="ä¸»æ•°å€¼", secondary_y=False)
            fig.update_yaxes(title_text="å¯¹æ¯”æ•°å€¼", secondary_y=True, showgrid=False)

            st.plotly_chart(fig, use_container_width=True)

            # --- è¯Šæ–­æŠ¥å‘Š ---
            if enable_diag and diag_result:
                st.subheader("ğŸ§  æ™ºèƒ½è¯Šæ–­æŠ¥å‘Š")
                color = "green" if diag_result["status"] == "normal" else (
                    "orange" if diag_result["status"] == "warning" else "red")
                msg = "\n".join(diag_result["messages"])

                # æ ¹æ®çŠ¶æ€æ˜¾ç¤ºä¸åŒé¢œè‰²çš„æç¤ºæ¡†
                if color == "green":
                    st.success(f"**è¯Šæ–­ç»“æœ**: \n\n{msg}")
                elif color == "orange":
                    st.warning(f"**è¯Šæ–­ç»“æœ**: \n\n{msg}")
                else:
                    st.error(f"**è¯Šæ–­ç»“æœ**: \n\n{msg}")

            # --- ç»Ÿè®¡è¡¨æ ¼ (å·²ä¿®å¤æ‹¬å·é—®é¢˜) ---
            st.subheader("ğŸ“Š è¯¦ç»†ç»Ÿè®¡æ•°æ®")
            if not df.empty:
                stats_data = []
                for col in y_left + y_right:
                    s = df[col]
                    stats_data.append({
                        "æ•°æ®æŒ‡æ ‡": col_map[col],
                        "æœ€å°å€¼": s.min(),
                        "æœ€å¤§å€¼": s.max(),
                        "å¹³å‡å€¼": s.mean(),
                        "å½“å‰å€¼": s.iloc[-1],
                        "æ³¢åŠ¨èŒƒå›´": s.max() - s.min()
                    })

                stats_df = pd.DataFrame(stats_data)

                # ğŸš€ ä¿®å¤ç‚¹ï¼šæå–è®¡ç®—æœ€å¤§å€¼çš„é€»è¾‘ï¼Œé¿å…åœ¨ column_config é‡Œå†™å¤ªå¤æ‚çš„å•è¡Œä»£ç 
                max_fluctuation = stats_df["æ³¢åŠ¨èŒƒå›´"].max() if not stats_df.empty else 100

                st.dataframe(
                    stats_df,
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        "æ•°æ®æŒ‡æ ‡": st.column_config.TextColumn("æŒ‡æ ‡åç§°", help="æ•°æ®åˆ—å"),
                        "æœ€å°å€¼": st.column_config.NumberColumn("æœ€å°å€¼ (Min)", format="%.2f"),
                        "æœ€å¤§å€¼": st.column_config.NumberColumn("æœ€å¤§å€¼ (Max)", format="%.2f"),
                        "å¹³å‡å€¼": st.column_config.NumberColumn("å¹³å‡å€¼ (Avg)", format="%.2f"),
                        "å½“å‰å€¼": st.column_config.NumberColumn("å½“å‰å€¼ (Current)", format="%.2f"),
                        # ä½¿ç”¨æå–å‡ºæ¥çš„ max_fluctuation å˜é‡
                        "æ³¢åŠ¨èŒƒå›´": st.column_config.ProgressColumn(
                            "æ³¢åŠ¨å¹…åº¦",
                            format="%.2f",
                            min_value=0,
                            max_value=max_fluctuation
                        ),
                    }
                )

                # ä¸‹è½½æŒ‰é’®
                csv = stats_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ğŸ“¥ ä¸‹è½½ç»Ÿè®¡æŠ¥å‘Š", csv, "report.csv", "text/csv")

        else:
            st.info("ğŸ‘ˆ è¯·é€‰æ‹© Y è½´æ•°æ®")

    except Exception as e:
        st.error(f"Error: {e}")